Many developers and system administrators manage servers by logging into them via SSH, making changes, and logging off. Some of these changes would be documented, some would not. If an admin needed to make the same change to many servers for example, changing one value in a config file, the admin would manually log into each server and repeatedly make this change.
If there were only one ot two changes in the course of a servers lifetime, and if the server were extremely simple running only one process, with one configuration, and a very simple firewall, and if every change were thoroghly documented, this process wouldnt be a problem.
But for almost every company in existence, servers are more complex most run tens, sometimrs hundreds of different applications. Most servers have complicated firewalls and dozens of tweaked configuration files. And even with change documentation, the manual process usually results in some servers or some steps being forgotten.
If the admins at these companies wanted to set up a new server exactly like one that is currently running, they would neet to spend a good deal of time going through all of the installed packages, documenting configurations, versions, and settings and they would need a spend a good deal of time going through all of the installed packages, documenting configurations, versions, and settings and they would spend a lot of unnecessary time manually reinstallin, updating, and tweaking everything to get the new server to run close to how the old server did.
Some admins may use shell scripts to try to reach some level of sanity, but Ive yet to see a complex shell script that handles all edge cases correctly while synchronizing multiple servers configuration and deploying new code.
